# Web UI for Self-Hosted Ollama Models

It is a user-friendly web interface developed with Angular that allows you to run Ollama's artificial intelligence models locally on your own computer. With this interface, you can interact with local models, send requests and receive responses without using terminal commands.
